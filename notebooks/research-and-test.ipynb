{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "241575c1",
   "metadata": {},
   "source": [
    "# 1- Fundamental libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7fc1883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scrapy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import bs4\n",
    "import matplotlib\n",
    "import xformers\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d5e4bb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "*** Versions ***\n",
      "----------------\n",
      "numpy==1.24.3\n",
      "pandas==1.5.3\n",
      "scipy==1.10.1\n",
      "scrapy==2.9.0\n",
      "seaborn==0.12.2\n",
      "requests==2.29.0\n",
      "bs4==4.12.2\n",
      "matplotlib==3.7.1\n",
      "xformers==0.0.20\n",
      "torch==2.0.1+cu117\n",
      "transformers==4.30.2\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*16)\n",
    "print('*** Versions ***')\n",
    "print('-'*16)\n",
    "print(f'numpy=={np.__version__}')\n",
    "print(f'pandas=={pd.__version__}')\n",
    "print(f'scipy=={scipy.__version__}')\n",
    "print(f'scrapy=={scrapy.__version__}')\n",
    "print(f'seaborn=={sns.__version__}')\n",
    "print(f'requests=={requests.__version__}')\n",
    "print(f'bs4=={bs4.__version__}')\n",
    "print(f'matplotlib=={matplotlib.__version__}')\n",
    "print(f'xformers=={xformers.__version__}')\n",
    "print(f'torch=={torch.__version__}')\n",
    "print(f'transformers=={transformers.__version__}')\n",
    "print('-'*16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96bcea",
   "metadata": {},
   "source": [
    "# 2- Explore Kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd1df642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviewer name</th>\n",
       "      <th>Review date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Comment count</th>\n",
       "      <th>Like count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aftersun (2022)</td>\n",
       "      <td>2022</td>\n",
       "      <td>Ã¢??Ã¢??Ã¢??Ã¢??Ã‚Â½</td>\n",
       "      <td>Tuomas</td>\n",
       "      <td>12-Jan-20</td>\n",
       "      <td>This review may contain spoilers.</td>\n",
       "      <td>130</td>\n",
       "      <td>22,44 6   likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joker (2019)</td>\n",
       "      <td>2019</td>\n",
       "      <td>Ã¢??Ã¢??Ã¢??Ã¢??Ã¢??</td>\n",
       "      <td>Joao</td>\n",
       "      <td>20-Dec-22</td>\n",
       "      <td>if youÃ¢??ve never swam in the ocean then of co...</td>\n",
       "      <td>1.8K</td>\n",
       "      <td>22,032 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puss in Boots: The Last Wish (2022)</td>\n",
       "      <td>2022</td>\n",
       "      <td>Ã¢??Ã‚Â½</td>\n",
       "      <td>NicoPico</td>\n",
       "      <td>15-Sep-22</td>\n",
       "      <td>Puss in Boots: Into the Pussy-Verse</td>\n",
       "      <td>6  2</td>\n",
       "      <td>21, 6   6   6   likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Banshees of Inisherin (2022)</td>\n",
       "      <td>2022</td>\n",
       "      <td>Ã¢??Ã¢??Ã¢??Ã¢??Ã¢??</td>\n",
       "      <td>Ella Kemp</td>\n",
       "      <td>8-Apr-22</td>\n",
       "      <td>I will NOT leave my donkey outside when IÃ¢??m sad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21, 6  09 likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everything Everywhere All at Once (2022)</td>\n",
       "      <td>2022</td>\n",
       "      <td>Ã¢??Ã¢??Ã‚Â½</td>\n",
       "      <td>CosmonautMarkie</td>\n",
       "      <td>14-Aug-19</td>\n",
       "      <td>Watch it and have fun before film Twitter tell...</td>\n",
       "      <td>355</td>\n",
       "      <td>20, 6  88 likes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Movie name Release Year           Rating  \\\n",
       "0                           Aftersun (2022)         2022   Ã¢??Ã¢??Ã¢??Ã¢??Ã‚Â½   \n",
       "1                              Joker (2019)         2019  Ã¢??Ã¢??Ã¢??Ã¢??Ã¢??   \n",
       "2       Puss in Boots: The Last Wish (2022)         2022            Ã¢??Ã‚Â½   \n",
       "3          The Banshees of Inisherin (2022)         2022  Ã¢??Ã¢??Ã¢??Ã¢??Ã¢??   \n",
       "4  Everything Everywhere All at Once (2022)         2022         Ã¢??Ã¢??Ã‚Â½   \n",
       "\n",
       "     Reviewer name Review date  \\\n",
       "0           Tuomas   12-Jan-20   \n",
       "1             Joao   20-Dec-22   \n",
       "2         NicoPico   15-Sep-22   \n",
       "3        Ella Kemp    8-Apr-22   \n",
       "4  CosmonautMarkie   14-Aug-19   \n",
       "\n",
       "                                              Review Comment count  \\\n",
       "0                  This review may contain spoilers.           130   \n",
       "1  if youÃ¢??ve never swam in the ocean then of co...          1.8K   \n",
       "2                Puss in Boots: Into the Pussy-Verse          6  2   \n",
       "3  I will NOT leave my donkey outside when IÃ¢??m sad           NaN   \n",
       "4  Watch it and have fun before film Twitter tell...           355   \n",
       "\n",
       "              Like count  \n",
       "0        22,44 6   likes  \n",
       "1           22,032 likes  \n",
       "2  21, 6   6   6   likes  \n",
       "3        21, 6  09 likes  \n",
       "4        20, 6  88 likes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://www.kaggle.com/datasets/joyshil0599/movie-reviews-dataset-10k-scraped-data\n",
    "df = pd.read_csv('../data/external/letterboxd-reviews.csv',encoding='latin_1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a258d",
   "metadata": {},
   "source": [
    "**poor data quality (for this application only)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4579158",
   "metadata": {},
   "source": [
    "# 3- Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "289c1b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Put this in config files\n",
    "TOP_250_ENDPOINT = 'https://letterboxd.com/dave/list/official-top-250-narrative-feature-films/'\n",
    "ALL_250_ENDOPOINTS = [TOP_250_ENDPOINT,TOP_250_ENDPOINT+'page/2/',TOP_250_ENDPOINT+'page/3/']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c70355",
   "metadata": {},
   "source": [
    "## 3.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c680050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_movies(endpoint):\n",
    "    \"\"\"\n",
    "    Get a list of movie links from the specified endpoint.\n",
    "\n",
    "    Parameters:\n",
    "        endpoint (str): The URL endpoint to scrape movie links from.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of movie links (URLs).\n",
    "    \"\"\"\n",
    "\n",
    "    BASE_ENDPOINT = 'https://letterboxd.com/'\n",
    "    all_movies = []\n",
    "\n",
    "    # Send a GET request to the endpoint and parse the HTML response\n",
    "    response = requests.get(endpoint)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    elements = soup.find_all(class_='poster-container numbered-list-item')\n",
    "\n",
    "    for element in elements:\n",
    "        # Extract the 'data-target-link' attribute from the 'poster' div\n",
    "        site = element.find('div', class_='poster').get('data-target-link')\n",
    "        all_movies.append(BASE_ENDPOINT + site)\n",
    "\n",
    "    return all_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b595fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(endpoint,max_reviews=20):\n",
    "    \"\"\"\n",
    "    Scrape review data for a movie from the specified endpoint.\n",
    "\n",
    "    Parameters:\n",
    "        endpoint (str): The URL endpoint to scrape review data from.\n",
    "        max_reviews (int, optional): The maximum number of reviews to scrape. Default is 20.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing movie review data with keys 'NAME', 'YEAR', 'DIRECTOR', 'SYNOPSIS',\n",
    "              'RATINGS', and 'TEXT'.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(endpoint)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extract relevant movie information from the webpage\n",
    "    film_name = soup.find(class_='headline-1 js-widont prettify').text\n",
    "    film_year = soup.find(class_='number').text\n",
    "    film_director = soup.find('span', class_='prettify').text\n",
    "    film_synopsys = soup.find(class_='truncate').text\n",
    "    \n",
    "    rating_review = []\n",
    "    text_review = []\n",
    "    \n",
    "    count_rev = 0 # Initialize the review count\n",
    "    page = 1  # Start with the first page of reviews\n",
    "    \n",
    "    # Loop until the desired number of reviews is reached\n",
    "    while count_rev < max_reviews:\n",
    "        response = requests.get(f'{endpoint}reviews/by/activity/page/{page}/')\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all review elements on the page\n",
    "        reviews = soup.find_all(class_='film-detail-content')\n",
    "\n",
    "        # Iterate over each review element\n",
    "        for review in reviews:\n",
    "            text = review.find(class_='-prose').text\n",
    "            stars = review.find(class_='rating')\n",
    "            \n",
    "            # Check if the review text is long enough and not truncated\n",
    "            if len(text) > 5:\n",
    "                if not (text[-3] == 'â€¦' or text[-4] == 'â€¦'):\n",
    "                    text_review.append(text+'***') # '***' is a separator\n",
    "                    \n",
    "                    # Check if a rating is available or set it to 'None'\n",
    "                    if stars is None:\n",
    "                        rating_review.append(' None ')\n",
    "                    else:\n",
    "                        rating_review.append(stars.text)\n",
    "                        \n",
    "                    count_rev += 1\n",
    "                    if count_rev == max_reviews:\n",
    "                        break\n",
    "                \n",
    "        # Move to the next reviews page\n",
    "        page += 1\n",
    "    \n",
    "    # Create a dictionary with the movie review data\n",
    "    data = {\n",
    "        'NAME': film_name,\n",
    "        'YEAR': film_year,\n",
    "        'DIRECTOR': film_director,\n",
    "        'SYNOPSYS': film_synopsys,\n",
    "        'RATINGS': rating_review,\n",
    "        'TEXT': text_review\n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c6007e",
   "metadata": {},
   "source": [
    "## 3.2 Get movie urls from the letterdboxd list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6d8832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucess!!!\n",
      "Excecution time: 1.01 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Define a list to store all movie links\n",
    "all_movies = []\n",
    "\n",
    "# Iterate over each endpoint in the list ALL_250_ENDOPOINTS\n",
    "for endpoint in ALL_250_ENDOPOINTS:\n",
    "    all_movies += get_movies(endpoint)\n",
    "end = time.time()\n",
    "\n",
    "total_time = round(end-start,2)\n",
    "print(f'Sucess!!!\\nExcecution time: {total_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b68702e",
   "metadata": {},
   "source": [
    "## 3.3 Get Metadata and short reviews for every movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "432664a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucess!!!\n",
      "Excecution time: 519.93 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Create an empty dictionary to store data for each movie\n",
    "data = {\n",
    "        'NAME': [],\n",
    "        'YEAR': [],\n",
    "        'DIRECTOR': [],\n",
    "        'SYNOPSYS': [],\n",
    "        'RATINGS': [],\n",
    "        'REVIEWS': []\n",
    "    }\n",
    "\n",
    "# Iterate over each movie in the list all_movies\n",
    "for movie in all_movies:\n",
    "    row = get_reviews(movie,max_reviews=20)\n",
    "    \n",
    "    data['NAME'].append(row['NAME'])\n",
    "    data['YEAR'].append(row['YEAR'])\n",
    "    data['DIRECTOR'].append(row['DIRECTOR'])\n",
    "    data['SYNOPSYS'].append(row['SYNOPSYS'])\n",
    "    data['RATINGS'].append(row['RATINGS'])\n",
    "    data['REVIEWS'].append(row['TEXT'])\n",
    "    \n",
    "# Create a DataFrame from the data dictionary\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "end = time.time()\n",
    "total_time = round(end-start,2)\n",
    "print(f'Sucess!!!\\nExcecution time: {total_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd806fb1",
   "metadata": {},
   "source": [
    "## 3.2 Save raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a0f1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/raw/LetterboxdTop250.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb933f",
   "metadata": {},
   "source": [
    "# 4- Clean and transform raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "631fa490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DIRECTOR</th>\n",
       "      <th>SYNOPSYS</th>\n",
       "      <th>RATINGS</th>\n",
       "      <th>REVIEWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harakiri</td>\n",
       "      <td>1962</td>\n",
       "      <td>Masaki Kobayashi</td>\n",
       "      <td>\\nDown-on-his-luck veteran Tsugumo HanshirÅ en...</td>\n",
       "      <td>[' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…Â½ ', ' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', '...</td>\n",
       "      <td>[' honor in the individual is virtue honor in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Come and See</td>\n",
       "      <td>1985</td>\n",
       "      <td>Elem Klimov</td>\n",
       "      <td>\\nThe invasion of a village in Byelorussia by ...</td>\n",
       "      <td>[' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…Â½ ', ' â˜…â˜…â˜…â˜…â˜… ', '...</td>\n",
       "      <td>[' as soon as this film ended i went online an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>\\nThe defense and the prosecution have rested ...</td>\n",
       "      <td>[' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…Â½ ', ' ...</td>\n",
       "      <td>[\" That was the best 1.5 hours of middle aged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seven Samurai</td>\n",
       "      <td>1954</td>\n",
       "      <td>Akira Kurosawa</td>\n",
       "      <td>\\nA samurai answers a village's request for pr...</td>\n",
       "      <td>[' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…Â½ ', ' â˜…â˜…â˜…â˜…â˜… ', '...</td>\n",
       "      <td>[' too many sweaty ass cheeks, 5 stars ***', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>\\nIn the continuing saga of the Corleone crime...</td>\n",
       "      <td>[' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', ' None ', ' ...</td>\n",
       "      <td>[\" young, totally fuckable al pacino and rober...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     NAME  YEAR              DIRECTOR  \\\n",
       "0                Harakiri  1962      Masaki Kobayashi   \n",
       "1            Come and See  1985           Elem Klimov   \n",
       "2            12 Angry Men  1957          Sidney Lumet   \n",
       "3           Seven Samurai  1954        Akira Kurosawa   \n",
       "4  The Godfather: Part II  1974  Francis Ford Coppola   \n",
       "\n",
       "                                            SYNOPSYS  \\\n",
       "0  \\nDown-on-his-luck veteran Tsugumo HanshirÅ en...   \n",
       "1  \\nThe invasion of a village in Byelorussia by ...   \n",
       "2  \\nThe defense and the prosecution have rested ...   \n",
       "3  \\nA samurai answers a village's request for pr...   \n",
       "4  \\nIn the continuing saga of the Corleone crime...   \n",
       "\n",
       "                                             RATINGS  \\\n",
       "0  [' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…Â½ ', ' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', '...   \n",
       "1  [' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…Â½ ', ' â˜…â˜…â˜…â˜…â˜… ', '...   \n",
       "2  [' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…Â½ ', ' ...   \n",
       "3  [' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…Â½ ', ' â˜…â˜…â˜…â˜…â˜… ', '...   \n",
       "4  [' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', ' â˜…â˜…â˜…â˜…â˜… ', ' None ', ' ...   \n",
       "\n",
       "                                             REVIEWS  \n",
       "0  [' honor in the individual is virtue honor in ...  \n",
       "1  [' as soon as this film ended i went online an...  \n",
       "2  [\" That was the best 1.5 hours of middle aged ...  \n",
       "3  [' too many sweaty ass cheeks, 5 stars ***', '...  \n",
       "4  [\" young, totally fuckable al pacino and rober...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/LetterboxdTop250.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3533d8dd",
   "metadata": {},
   "source": [
    "## 4.1- Save to kaggle contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a7b0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SYNOPSYS'] = df['SYNOPSYS'].str[1:-1]\n",
    "df.to_csv('../data/interim/LetterboxdTop250-5000reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16fd90b",
   "metadata": {},
   "source": [
    "## 4.2- Format for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd8a685e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RATINGS format: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "df['RATINGS'] = df['RATINGS'].str[1:-1].str.split(', ')\n",
    "print(f'RATINGS format: {type(df[\"RATINGS\"][0])}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0c01f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEWS format: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "df['REVIEWS'] = df['REVIEWS'].str[1:-1].str.split('\\*\\*\\*')\n",
    "print(f'REVIEWS format: {type(df[\"REVIEWS\"][0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9c3593",
   "metadata": {},
   "source": [
    "## 4.3- prepare for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee5a4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for convinient workflow\n",
    "data_dict = df[['NAME','RATINGS','REVIEWS']].set_index('NAME').to_dict()\n",
    "\n",
    "#Structure:\n",
    "#{'RATINGS': {'NAME'}: stars,\n",
    "# 'SYNOPSYS':{'NAME'}: comments}\n",
    "\n",
    "\n",
    "#'RATINGS': primary key\n",
    "#'NAME': secondary key\n",
    "#stars: list (20 elements)\n",
    "#comments: list (20 elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b945ee1",
   "metadata": {},
   "source": [
    "## 4.4 Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11585675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean review example:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' wait can we normalize calling something youâ€™ve only seen once, your favorite movie of all time? '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_dict = {}\n",
    "for key, value in data_dict['REVIEWS'].items():\n",
    "    clean_rev = []\n",
    "    \n",
    "    for review in value:\n",
    "        # Remove unwanted characters from each review\n",
    "        string = review.replace(\"',\",\"\").replace(\"' \",\"\").replace(\"\\'\",\"\").replace('AAAA','')\n",
    "        clean_rev.append(string)\n",
    "        \n",
    "    #Drop the last empty comment    \n",
    "    rev_dict[key] = clean_rev[:-1]\n",
    "    \n",
    "# Update the 'REVIEWS' key in data_dict with the cleaned review texts\n",
    "data_dict['REVIEWS'] = rev_dict\n",
    "\n",
    "print('Clean review example:')\n",
    "data_dict['REVIEWS']['Harakiri'][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801b70f",
   "metadata": {},
   "source": [
    "## 4.5- Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17b1d18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rating format example: ' â˜…â˜…â˜…â˜…â˜… '\n"
     ]
    }
   ],
   "source": [
    "print(f'Raw rating format example: {data_dict[\"RATINGS\"][\"Harakiri\"][6]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6537d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_rating(raw_string):\n",
    "    \"\"\"\n",
    "    Extract the numerical rating from the raw_data string.\n",
    "\n",
    "    Parameters:\n",
    "        raw_string (str): A string representing the raw rating data, which may contain 'â˜…' for full stars and 'Â½' for half star.\n",
    "\n",
    "    Returns:\n",
    "        float: The numerical rating extracted from the raw_data string. If raw_data is 'None', it returns 0.0.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove the leading and trailing characters\n",
    "    stars = raw_string[2:-2]  \n",
    "    count = 0.0\n",
    "\n",
    "    if stars != 'None':\n",
    "        # Iterate over each character in stars\n",
    "        for char in stars:\n",
    "            if char == 'â˜…':\n",
    "                count += 1\n",
    "            elif char == 'Â½':\n",
    "                count += 0.5\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be7862c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed rating format example: 5.0\n"
     ]
    }
   ],
   "source": [
    "num_dict = {}\n",
    "for key,value in data_dict['RATINGS'].items():\n",
    "    num_values = []\n",
    "    \n",
    "    for stars in value:\n",
    "        # Call the get_num_rating() function to extract the numerical rating\n",
    "        num_values.append(get_num_rating(stars))\n",
    "    num_dict[key] = num_values\n",
    "    \n",
    "# Update the 'RATINGS' key in data_dict with the extracted numerical ratings\n",
    "data_dict['RATINGS'] = num_dict\n",
    "\n",
    "print(f'Transformed rating format example: {data_dict[\"RATINGS\"][\"Harakiri\"][6]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db9495",
   "metadata": {},
   "source": [
    "# 5- Natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af41118",
   "metadata": {},
   "source": [
    "## 5.1 Usefull functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39cbab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(scores):\n",
    "    \"\"\"\n",
    "    Map the model output scores to human-readable labels.\n",
    "\n",
    "    Parameters:\n",
    "        scores (numpy.ndarray): An array containing the model's output scores for each class.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are human-readable labels ('Negative', 'Neutral', 'Positive')\n",
    "              and the values are the corresponding scores from the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a dictionary to map class indices to human-readable labels\n",
    "    # info in: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\n",
    "    labels = {\n",
    "    0:'Negative',\n",
    "    1:'Neutral',\n",
    "    2:'Positive'\n",
    "    }\n",
    "    \n",
    "    result = {}\n",
    "    for i in range(scores.shape[0]):\n",
    "        result[labels[i]] = scores[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8ded6",
   "metadata": {},
   "source": [
    "## 5.2 CPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32b8ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "\n",
    "MODEL_NAME = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "#model.save_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af6520",
   "metadata": {},
   "source": [
    "It is necessary to generate a validation function for the input data. This will be done later with the model already in production, for now we are going to use TRY EXCEPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3db6c5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ğŸ’¼ â€¢ ğŸ•° â€¢ ğŸ—„ â€¢ ğŸ“° â€¢ ğŸ”‘ â€¢ ğŸšª â€¢ ğŸ¸ â€¢ ğŸ¸ â€¢ ğŸ¥‚{ğ™µğš›ğšŠğš—} ğš†ğš‘ğš¢ ğšğš˜ ğš™ğšğš˜ğš™ğš•ğš ğš‘ğšŠğšŸğš ğšğš˜ ğš•ğš˜ğšŸğš ğš™ğšğš˜ğš™ğš•ğš ğšŠğš—ğš¢ğš ğšŠğš¢?ğ•„ğ•†ğ•ğ•€ğ”¼-ğ•ğ•€ğ•Šğ”¼, ğ•‹â„ğ”¼â„ğ”¼ â„ğ”¸ğ•Š â„•ğ”¼ğ•ğ”¼â„ ğ”¹ğ”¼ğ”¼â„• ğ”¸â„•ğ•ğ•‹â„ğ•€â„•ğ”¾ ğ•ƒğ•€ğ•‚ğ”¼ ğ•€ğ•‹ - ğ•ƒğ•†ğ•ğ”¼-ğ•ğ•€ğ•Šğ”¼, ğ•ƒğ”¸ğ•Œğ”¾â„-ğ•ğ•€ğ•Šğ”¼ ğ•†â„ ğ•†ğ•‹â„ğ”¼â„-ğ•ğ•€ğ•Šğ”¼!ğ“ğ¡ğ¢ğ¬ ğ¢ğ¬ ğ¨ğ§ğ ğ¨ğŸ ğ­ğ¡ğ¨ğ¬ğ ğœğ¥ğšğ¬ğ¬ğ¢ğœ ğ¦ğ¨ğ¯ğ¢ğğ¬ ğ­ğ¡ğšğ­ ğ¢ğ¬ ğ­ğ¢ğ¦ğğ¥ğğ¬ğ¬. ğ–ğ¢ğ­ğ­ğ² ğğ¢ğšğ¥ğ¨ğ ğ®ğ ğšğ§ğ ğš ğ¬ğ¢ğ¦ğ©ğ¥ğ ğ²ğğ­ ğğŸğŸğğœğ­ğ¢ğ¯ğ ğ§ğšğ«ğ«ğšğ­ğ¢ğ¯ğ ğ¦ğšğ¤ğ ğŸğ¨ğ« ğªğ®ğ¢ğ­ğ ğšğ§ ğ¢ğ§ğ­ğğ«ğğ¬ğ­ğ¢ğ§ğ  ğ°ğšğ­ğœğ¡, ğ¡ğ¨ğ°ğğ¯ğğ«, ğˆ ğŸğğğ¥ ğ¢ğ­ ğ¥ğ¨ğ¬ğ­ ğ¬ğ¨ğ¦ğ ğ¨ğŸ ğ¢ğ­ğ¬ ğ¬ğ©ğšğ«ğ¤ ğ›ğ² ğ­ğ¡ğ ğ¡ğšğ¥ğŸğ°ğšğ² ğ¦ğšğ«ğ¤. ğ“ğ¡ğ ğ­ğ¨ğ§ğğ¬ ğ¬ğ¡ğ¢ğŸğ­ğğ ğŸğ«ğ¨ğ¦ ğš ğ¥ğ¢ğ ğ¡ğ­ğ¡ğğšğ«ğ­ğğ ğ«ğ¨ğ¦-ğœğ¨ğ¦ ğ­ğ¨ ğš ğ¦ğ¨ğ«ğ ğ©ğ«ğğğ¢ğœğ­ğšğ›ğ¥ğ ğğ«ğšğ ğ ğ¢ğ§ğ  ğğ«ğšğ¦ğš. ğğ¨ğ§ğğ­ğ¡ğğ¥ğğ¬ğ¬, ğˆ ğğ§ğ£ğ¨ğ²ğğ ğ­ğ¡ğ ğŸğ¢ğ«ğ¬ğ­ ğ¡ğšğ¥ğŸ ğğ§ğ¨ğ®ğ ğ¡ ğ­ğ¨ ğ¨ğ¯ğğ«ğ¥ğ¨ğ¨ğ¤ ğ¦ğ² ğ¬ğ¥ğ¢ğ ğ¡ğ­ ğğ¢ğ¬ğšğ©ğ©ğ¨ğ¢ğ§ğ­ğ¦ğğ§ğ­ ğ›ğ² ğ­ğ¡ğ ğğ§ğ. \n",
      "\", Ø¨Ø´Ø§Ø¹Ø±ÙŠØªÙ‡ Ø§Ù„ÙØ±ÙŠØ¯Ø© ÙˆØ§Ù„Ø£Ø®Ø§Ø°Ø© Ù…Ù…Ø²ÙˆØ¬Ø© Ø¨Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ø±Ø§Ø¦Ø¹Ø© Ø¬Ø¯Ø§.. ØµÙ†Ø¹ Ù„Ù†Ø§ Ø«ÙŠÙˆ Ø£Ù†Ø¬ÙŠÙ„ÙˆØ¨ÙˆÙ„ÙˆØ³ ØªØ­ÙØªÙ‡ Ù‡Ø§ØªÙ‡ ÙˆØ¹Ø§Ù„Ø¬ ÙÙŠÙ‡Ø§ Ø¨Ù…Ù†ØªÙ‡Ù‰ Ø§Ù„Ø¬Ù…Ø§Ù„ÙŠØ© Ù‡ÙˆØ§Ø¬Ø³ ÙˆØ°ÙƒØ±ÙŠØ§Øª Ø±Ø¬Ù„ ÙŠØ¯Ù†Ùˆ Ù…Ù† Ø§Ù„ÙÙ†Ø§Ø¡.. ÙŠÙ‚ØªØ±Ø¨ Ù…Ù† Ø§Ù„Ø§Ø±ØªØ­Ø§Ù„ Ø¥Ù„Ù‰ Ø¹Ø§Ù„Ù… Ø¢Ø®Ø± ÙˆÙ‡Ùˆ ÙÙŠ Ù‚Ù…Ø© Ø§Ù„Ø£Ø³Ù‰ ÙˆØ§Ù„Ù†Ø¯Ù… Ø¹Ù„Ù‰ Ø¹Ù…Ø± Ù…Ø¯ÙŠØ¯ Ù„Ù† ÙŠØ¹ÙˆØ¯.\" Ø±Ø¬Ù„ ÙŠØ­ØªØ¶Ø±ØŒ ÙŠÙˆÙ…Ù‡ Ø§Ù„Ø£Ø®ÙŠØ±. ÙƒÙŠÙ ØªÙ‚Ø¶ÙŠ ÙŠÙˆÙ…Ùƒ Ø§Ù„Ø£Ø®ÙŠØ±ØŸ Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ­Ø¯Ø« Ù„Ù†Ø§ØŸ Ù…Ø§Ø°Ø§ Ø³Ù†ÙØ¹Ù„ Ø¨Ø§Ù„Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ù„Ù†Ø§ØŸ Ù‡Ù„ ØªØªØ£Ù…Ù„ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„ØªÙŠ Ø¹Ø´ØªÙ‡Ø§ØŒ Ø£Ù… Ø£Ù†Ùƒ ØªØ³Ù…Ø­ Ù„Ù†ÙØ³Ùƒ Ø¨Ø£Ù† ØªÙ†Ø³Ø§Ù‚ØŒ ØªÙ†ÙƒØ´Ù Ø£Ù…Ø§Ù… ÙƒÙ„ Ø§Ù„Ù…ØµØ§Ø¯ÙØ§Øª: ØªØªØ¹Ù‚Ø¨ Ø´Ø®ØµØ§ Ù…Ø§ØŒ ØªÙØªØ­ Ù†Ø§ÙØ°Ø©ØŒ ØªÙ„ØªÙ‚ÙŠ Ø¨Ø´Ø®Øµ Ù„Ø§ ØªØ¹Ø±ÙÙ‡ØŒ ØªÙØªØ­ Ù†ÙØ³Ùƒ Ù„ÙƒÙ„ Ù…Ø§ ÙŠØ­Ø¯Ø«ØŒ Ù„Ù„Ù…Ø¬ÙŠØ¡ ØºÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ØŒ Ù„Ù„Ø°ÙŠ Ù„Ø§ ÙŠØ±ØªØ¨Ø· Ù„ÙƒÙ† ÙŠØªØ¶Ø­ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ø£Ù†Ù‡ ÙŠØ±ØªØ¨Ø·ØŸ \" - Ø«ÙŠÙˆØ¯ÙˆØ±ÙˆØ³ Ø£Ù†Ø¬ÙŠÙ„ÙˆØ¨ÙˆÙ„ÙˆØ³ \n",
      "\", ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ \n",
      " \"She\\ll never grow old!\"Satoshi Kon is Cinema \\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003Cinema is Reality \\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003Reality is History \\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2002\\u200aHistory is Time \\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u200a\\u200a\\u200a\\u200a\\u200aTime is Life\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u2003\\u200a\\u200a\\u2002\\u200a\\u200a\\u200a\\u200a\\u200a\\u200a\\u200aLife is AC I N E M AT\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u200aIR\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u200a\\u200a\\u200a\\u200aLE\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u200aLS\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u200a\\u200a\\u200a\\u200aES\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u200a\\u200a\\u200a\\u200aN\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u200a\\u200aN\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u200a\\u200aI\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u200a\\u200aU\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u2005\\u200a\\u200aM \n",
      " ÙŠÙ‚ÙˆÙ„ Ù…Ø®Ù…Ù„Ø¨Ø§Ù Ø¹Ù† Ø§Ù„ÙÙ„Ù…:\\xa0ÙƒØ§Ù† Ø´Ø¨Ù‡ Ø±ÙˆØ§Ø¦ÙŠ ÙˆØ§Ù„Ø°ÙŠ Ø§Ø³ØªØ®Ø¯Ù…ØªÙ‡ Ù„Ø¥ÙŠØµØ§Ù„ Ù†ØµÙŠØ­ØªÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹. Ù„ÙƒÙ†Ù†ÙŠ Ø£ÙŠØ¶Ù‹Ø§ Ø§Ù†ØªÙ‚Ø¯Øª Ø°Ø§ØªÙŠ Ø§Ù„Ø£ØµØºØ± Ø³Ù†Ù‹Ø§ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø±Ù…Ø²ÙŠØ© ØŒ Ø­ØªÙ‰ Ø£Ù†ØªÙ‚Ø¯ Ø«ÙˆØ±ØªÙ†Ø§ ØŒ Ø­ÙŠØ« ÙƒØ§Ù† Ù…Ù† Ø§Ù„Ù…Ø³ØªØ­ÙŠÙ„ ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§ Ø£Ù† Ø£Ù†ØªÙ‚Ø¯ Ø§Ù„Ø«ÙˆØ±Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø¨Ø§Ø´Ø±Ø© ØŒ Ø­Ø§ÙˆÙ„Øª Ø£Ù† Ø£ØªØ¬Ø§ÙˆØ² Ù‚ØµØªÙŠ Ø§Ù„Ø´Ø®ØµÙŠØ© ØŒ ÙƒÙŠ Ø£Ø´ÙŠØ± Ø¥Ù„Ù‰ Ù…Ø´ÙƒÙ„Ø© Ù‡ÙŠÙƒÙ„ÙŠØ© Ø£ÙƒØ¨Ø±ØŒ ÙƒØ§Ù„Ø¹Ù†Ù Ø§Ù„Ù…Ù„Ø§Ø²Ù… Ù„Ù„Ø«ÙˆØ±Ø© ÙˆØ£Ù† Ø£Ø¹Ø±Ø¶ Ù†Ø³Ø®Ø© ØºÙŠØ± Ø¹Ù†ÙŠÙØ© Ù…Ù†Ù‡Ø§Ø§Ø°Ø§ Ù‡Ø§Ù„ÙÙŠÙ„Ù… Ù…Ùˆ Ø£Ù†Ù‚Ù‰ ÙÙ„Ù… ØªØ§Ø¨Ø¹ØªÙ‡ Ø§Ù†Ø§ Ù…Ø§ Ø§ÙÙ‡Ù… ØŒ Ø¬Ù…Ø§Ù„ÙŠØ© Ø±Ø³Ø§Ù„Ù‡ ÙˆØ¨Ø³Ø§Ø·Ø© ØªÙ‚Ø¯ÙŠÙ… ØªØ¯Ù‘Ø±Ø³ Ø­Ù‚ÙŠÙ‚Ø©Ø±Ø³Ø§Ù„Ù‡ ÙŠÙ‡Ø¯ÙŠÙ‡Ø§ Ø§Ù„Ù…Ø®Ø±Ø¬ Ù„Ù†ÙØ³Ù‡ ÙÙŠ Ø§Ù„Ù…Ø§Ø¶ÙŠ ÙˆÙ„Ø³Ø§Ù† Ø­Ø§Ù„Ù‡ ÙŠÙ‚ÙˆÙ„ Ø§Ù„Ø£Ù…ÙˆØ± Ù‚Ø¯ Ù„Ø§ ØªØ­ØªØ§Ø¬ Ø§Ù„Ù‰ Ø§Ù„Ø¹Ù†Ù Ø­ØªÙ‰ ØªØªØ­ÙˆÙ„ Ù„Ù„Ø£ÙØ¶Ù„ ÙˆØ§Ø³ØªØ´Ø¹Ø±Øª Ø§Ù† Ø±Ø³Ù… Ø¨Ø¢Ø®Ø± Ø§Ù„ÙÙ„Ù… Ø§Ù„Ø´ÙŠØ¡ Ø§Ù„Ù„ÙŠ ÙˆØ¯Ù‡ Ø­ØµÙ„ Ù„Ù‡Ø£Ø¹Ø¬Ø² Ø£Ø¹Ø¬Ø² Ø¹Ù† ÙˆØµÙ Ù‡Ø§Ù„ÙÙŠÙ„Ù…. \n"
     ]
    }
   ],
   "source": [
    "sentiment_dict = {}\n",
    "for key,values in data_dict['REVIEWS'].items():\n",
    "    \n",
    "    sentiment_list = []\n",
    "    for review in values:\n",
    "        # Tokenize the review text and convert it to PyTorch tensors\n",
    "        encoded_input = tokenizer(review, return_tensors='pt')\n",
    "        try:\n",
    "            output = model(**encoded_input)\n",
    "        except:\n",
    "            # If an exception occurs, set labels to 'Wrong input'\n",
    "            labels = 'Wrong input'\n",
    "            print(review)\n",
    "        else:\n",
    "            # Extract the model's output scores, apply softmax, and get human-readable labels\n",
    "            scores = softmax(output[0][0].detach().numpy())\n",
    "            labels = get_labels(scores)\n",
    "        finally:\n",
    "            sentiment_list.append(labels)\n",
    "    \n",
    "    # Assign the sentiment_list to the key in sentiment_dict\n",
    "    sentiment_dict[key] = sentiment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9cb79032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Negative': 0.16631296, 'Neutral': 0.32354698, 'Positive': 0.5101401}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dict['12 Angry Men'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7608109",
   "metadata": {},
   "source": [
    "### 5.2.1 Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55606ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/processed/sentiment_analysis.pkl', 'wb') as file:\n",
    "    pickle.dump(sentiment_dict, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60cd4b",
   "metadata": {},
   "source": [
    "## 5.3 GPU version\n",
    "Future work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
